{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Migrating data from Google cloud storage(Data lake) to BigQuery(Data warehouse) via Dataproc (Apache Spark) -- ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data\n",
    "\n",
    "The raw data from kaggle(kaggle datasets download -d yelp-dataset/yelp-dataset) has already download to Google cloud storage (data lake) via VM engine (google cloud). The data are json files. In Spark, these can be read using spark.read.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext, Row\n",
    "gcs_bucket='t-osprey-337221-yelp'\n",
    "spark = SparkSession.builder.appName(\"yelp\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "business = \"gs://\"+gcs_bucket+\"//.yelp-dataset/yelp_academic_dataset_business.json\"\n",
    "review =\"gs://\"+gcs_bucket+\"//.yelp-dataset/yelp_academic_dataset_review.json\"\n",
    "business_df = spark.read.json(business)\n",
    "review_df = spark.read.json(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create tempview for sparksql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df.createOrReplaceTempView(\"business_table\")\n",
    "review_df.createOrReplaceTempView(\"review_table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### only select restaurant and is open from business table, and do column selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df = spark.sql(\"\"\"\n",
    "                            select \n",
    "                            business_id, name, city, latitude, longitude, review_count, stars, state, address\n",
    "                            from \n",
    "                            business_table\n",
    "                            where categories like '%Restaurants%'and is_open=1\n",
    "                            \"\"\")\n",
    "restaurant_df.show(5)\n",
    "restaurant_df.createOrReplaceTempView(\"restaurant_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "            select count(*) from restaurant_table\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if business_id has duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "            select count(business_id) as num from restaurant_table group by business_id having num >1\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if business_id and stars has Null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "            select * from restaurant_table where business_id IS NULL or stars is null\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column selection from review table, and stars column is not null, user_id is not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = spark.sql(\"\"\"\n",
    "                        select review_id, business_id, user_id, cool, date, funny, stars as review_stars, useful\n",
    "                        from \n",
    "                        review_table\n",
    "                        where stars is not null and review_id is not null and user_id is not null and business_id is not null\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.show(5)\n",
    "review_df.createOrReplaceTempView(\"review_edit_table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check if review_id has duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "            select count(review_id) from review_edit_table group by review_id having count(review_id)>1\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "            select count(*) from review_edit_table\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### caculate total review number and average stars for each business_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "            select business_id, count(business_id) as num, avg(review_stars) from review_edit_table \n",
    "            group by business_id order by num desc\"\"\").cache().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge business table and review together, using right join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_restaurant = spark.sql(\"\"\" select \n",
    "          restaurant.*, review_id, user_id, cool, date, funny, review_stars, useful\n",
    "          from \n",
    "          restaurant_table restaurant \n",
    "          right join review_edit_table rt \n",
    "          on restaurant.business_id = rt.business_id\"\"\"\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_restaurant.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_restaurant.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save yelp_restaurant table to bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_restaurant.write.format('bigquery') \\\n",
    "  .option('csv', 'yelp.yelp_restaurant') \\\n",
    "  .save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
